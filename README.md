# Msc-project
AI-Enhanced UAV IDS for UAVs  A clean, reproducible implementation of a multi-class, explainable Intrusion Detection System (IDS) for UAV networks. The project trains LightGBM models on UAV-NIDD cases and ships a near-realtime monitoring web app (Gradio) with per-class thresholds, threat-intel context (CVE / MITRE), and LIME explanations.
This repository contains the implementation of a multi-class, explainable Intrusion Detection System (IDS) for Unmanned Aerial Vehicle (UAV) networks. The system combines the efficiency of the LightGBM machine learning algorithm with the interpretability of LIME (Local Interpretable Model-Agnostic Explanations). It has been trained and evaluated using the UAV-NIDD dataset, which includes multiple UAV communication scenarios and a diverse range of cyberattacks. The IDS has been designed not only for accuracy but also for transparency, near-real-time monitoring, and practical deployment feasibility.

The training pipeline prepares and merges UAV-NIDD dataset cases, standardises attack labels, performs feature alignment, and applies median imputation for missing values. LightGBM is used as the core detection algorithm, chosen for its ability to scale efficiently to high-dimensional network traffic while remaining lightweight enough for UAV environments. The integration of LIME enables interpretable outputs by identifying which features contribute most to each prediction, ensuring that the IDS is not treated as a black-box model.

The repository also includes a Gradio-based monitoring application that demonstrates how the IDS could function in a near-real-time UAV network environment. The interface streams predictions continuously, raises alerts when anomalies are detected, and provides contextualised insights through LIME visualisations and threat intelligence mappings (CVE and MITRE ATT&CK references). This approach bridges the gap between academic research and operational deployment by providing situational awareness to UAV operators in a user-friendly dashboard.

Outputs generated during training and evaluation include confusion matrices, classification reports with per-class precision, recall and F1-scores, training versus validation curves (including zoomed views near the optimal iteration), feature importance plots, and LIME explanations for selected predictions. These visualisations support both technical evaluation and thesis documentation, providing a comprehensive understanding of the modelâ€™s performance and behaviour across different UAV cases.

The repository is structured with separate modules for training, monitoring, and output storage. Training scripts process UAV-NIDD cases such as UAVCase1, GCSCase3, and AccessPoint2, while exporting model bundles (including the trained model, label encoder, and feature specification) for later use. The monitoring application loads these bundles and can stream either real dataset rows or synthetic traffic based on feature medians, offering a lightweight but realistic simulation of operational IDS performance. All experimental runs save their results to an organised directory containing plots, reports, and model outputs, making the workflow fully reproducible.

This project is intended for academic and research purposes only. It demonstrates that an AI-based IDS can deliver multi-class detection, explainable insights, and lightweight near-real-time monitoring in UAV environments. By leveraging UAV-specific datasets and explainable AI, the work provides a pathway toward secure UAV operations and highlights future opportunities for extending IDS solutions to live UAV networks and more advanced deep learning models.
